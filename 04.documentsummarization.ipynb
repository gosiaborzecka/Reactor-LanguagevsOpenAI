{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = [\n",
    "        \"\"\"### Bias in Artificial Intelligence: A Deep Dive\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "Bias in Artificial Intelligence (AI) is a critical issue that has gained significant attention in recent years. AI systems, from simple machine learning models to complex neural networks, have permeated various aspects of our lives, including healthcare, finance, law enforcement, and social media. While AI offers immense benefits, the prevalence of bias in these systems poses serious ethical, social, and technical challenges.\n",
    "\n",
    "#### Understanding Bias in AI\n",
    "\n",
    "1. **Definition and Origin**: Bias in AI refers to systematic and unfair discrimination in the outcomes of AI systems. It often stems from the data used to train these systems. If the training data is unrepresentative or contains historical biases, the AI system is likely to perpetuate or even exacerbate these biases.\n",
    "\n",
    "2. **Types of Bias**: \n",
    "    - *Data Bias*: Occurs when the dataset is not representative of the real-world scenario it aims to model.\n",
    "    - *Algorithmic Bias*: Introduced by the assumptions and choices made during the algorithm development process.\n",
    "    - *Confirmation Bias*: Arises when an AI system is designed in a way that it reinforces the beliefs or prejudices of its creators.\n",
    "\n",
    "#### Impacts of Bias\n",
    "\n",
    "1. **Social and Ethical Implications**: Bias in AI can lead to unfair treatment of certain groups, amplifying existing social inequalities. In areas like recruitment, credit scoring, and law enforcement, biased AI systems can result in unfair or discriminatory outcomes.\n",
    "\n",
    "2. **Legal and Regulatory Concerns**: Many countries and regions are now looking into regulations to prevent biased AI practices. The European Unionâ€™s General Data Protection Regulation (GDPR), for instance, includes provisions that relate to automated decision-making and profiling.\n",
    "\n",
    "3. **Economic Effects**: Businesses relying on biased AI systems risk making flawed decisions, potentially leading to financial losses or reputational damage.\n",
    "\n",
    "#### Case Studies\n",
    "\n",
    "1. **Recruitment Tools**: Certain AI-driven recruitment tools have been found to exhibit gender bias, favoring male candidates over female candidates in certain job roles, based on biased historical hiring data.\n",
    "\n",
    "2. **Criminal Justice Systems**: AI systems used in predictive policing and sentencing have sometimes unfairly targeted minority communities, reflecting historical biases present in the criminal justice data.\n",
    "\n",
    "3. **Healthcare Algorithms**: Research has shown that some healthcare-related AI systems have provided less accurate diagnoses for certain racial groups, primarily due to the underrepresentation of these groups in the training data.\n",
    "\n",
    "#### Mitigating Bias in AI\n",
    "\n",
    "1. **Diverse and Representative Data**: Ensuring that training datasets are diverse and representative can help reduce data biases. This includes considering factors like race, gender, socio-economic status, and geography.\n",
    "\n",
    "2. **Algorithmic Transparency and Explainability**: Developing algorithms that are transparent and explainable can help identify and mitigate biases. This transparency is crucial for sensitive applications like healthcare and criminal justice.\n",
    "\n",
    "3. **Regular Auditing and Testing**: Regularly auditing AI systems for biased outcomes and continuously testing these systems in real-world scenarios are essential practices.\n",
    "\n",
    "4. **Ethical AI Frameworks**: Implementing ethical AI frameworks and guidelines in organizations can help in making conscious efforts to avoid biases in AI systems. This includes ethical training for AI developers and practitioners.\n",
    "\n",
    "5. **Community and Stakeholder Engagement**: Involving a diverse range of stakeholders, including those who are most likely to be affected by AI decisions, in the development process can provide valuable insights into potential biases.\n",
    "\n",
    "#### Future Perspectives\n",
    "\n",
    "Looking forward, the challenge of bias in AI is not insurmountable. With the increasing awareness and evolving technological tools, there is a growing potential to develop AI systems that are fairer and more equitable. The future of AI should be inclusive, ensuring that the benefits of AI are accessible to all sections of society and do not perpetuate existing disparities. \n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "Bias in AI is a multifaceted issue that requires a concerted effort from technologists, policymakers, and society at large to address. By acknowledging and actively working to mitigate bias, the future of AI can be shaped into a tool that works equitably for the betterment of all.\"\"\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary extracted: \n",
      "### Bias in Artificial Intelligence: A Deep Dive\n",
      " Bias in Artificial Intelligence (AI) is a critical issue that has gained significant attention in recent years.\n",
      " AI systems, from simple machine learning models to complex neural networks, have permeated various aspects of our lives, including healthcare, finance, law enforcement, and social media.\n",
      " While AI offers immense benefits, the prevalence of bias in these systems poses serious ethical, social, and technical challenges.\n",
      " #### Understanding Bias in AI\n",
      " 1. **Definition and Origin**: Bias in AI refers to systematic and unfair discrimination in the outcomes of AI systems.\n",
      " It often stems from the data used to train these systems.\n",
      " If the training data is unrepresentative or contains historical biases, the AI system is likely to perpetuate or even exacerbate these biases.\n",
      " 2. **Types of Bias**:\n",
      " In areas like recruitment, credit scoring, and law enforcement, biased AI systems can result in unfair or discriminatory outcomes.\n",
      " 2. **Criminal Justice Systems**: AI systems used in predictive policing and sentencing have sometimes unfairly targeted minority communities, reflecting historical biases present in the criminal justice data.\n",
      " #### Mitigating Bias in AI\n",
      " This transparency is crucial for sensitive applications like healthcare and criminal justice.\n",
      " 4. **Ethical AI Frameworks**: Implementing ethical AI frameworks and guidelines in organizations can help in making conscious efforts to avoid biases in AI systems.\n",
      " This includes ethical training for AI developers and practitioners.\n",
      " Looking forward, the challenge of bias in AI is not insurmountable.\n",
      " With the increasing awareness and evolving technological tools, there is a growing potential to develop AI systems that are fairer and more equitable.\n",
      " The future of AI should be inclusive, ensuring that the benefits of AI are accessible to all sections of society and do not perpetuate existing disparities.\n",
      " Bias in AI is a multifaceted issue that requires a concerted effort from technologists, policymakers, and society at large to address.\n",
      " By acknowledging and actively working to mitigate bias, the future of AI can be shaped into a tool that works equitably for the betterment of all.\n"
     ]
    }
   ],
   "source": [
    "key = \"{AzureLanguageKey}\"\n",
    "endpoint = \"{AzureLanguageEndpoint}\"\n",
    "\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Authenticate the client using your key and endpoint \n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n",
    "\n",
    "# Example method for summarizing text\n",
    "def sample_extractive_summarization(client):\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from azure.ai.textanalytics import (\n",
    "        TextAnalyticsClient,\n",
    "        ExtractiveSummaryAction\n",
    "    ) \n",
    "    \n",
    "    poller = client.begin_analyze_actions(\n",
    "        document,\n",
    "        actions=[\n",
    "            ExtractiveSummaryAction(max_sentence_count=20)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    document_results = poller.result()\n",
    "    for result in document_results:\n",
    "        extract_summary_result = result[0]  # first document, first result\n",
    "        if extract_summary_result.is_error:\n",
    "            print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "                extract_summary_result.code, extract_summary_result.message\n",
    "            ))\n",
    "        else:\n",
    "            print(\"Summary extracted: \\n{}\".format(\n",
    "                \"\\n \".join([sentence.text for sentence in extract_summary_result.sentences]))\n",
    "            )\n",
    "\n",
    "sample_extractive_summarization(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['### Bias in Artificial Intelligence: A Deep Dive\\n\\n#### Introduction\\n\\nBias in Artificial Intelligence (AI) is a critical issue that has gained significant attention in recent years. AI systems, from simple machine learning models to complex neural networks, have permeated various aspects of our lives, including healthcare, finance, law enforcement, and social media. While AI offers immense benefits, the prevalence of bias in these systems poses serious ethical, social, and technical challenges.\\n\\n#### Understanding Bias in AI\\n\\n1. **Definition and Origin**: Bias in AI refers to systematic and unfair discrimination in the outcomes of AI systems. It often stems from the data used to train these systems. If the training data is unrepresentative or contains historical biases, the AI system is likely to perpetuate or even exacerbate these biases.\\n\\n2. **Types of Bias**: \\n    - *Data Bias*: Occurs when the dataset is not representative of the real-world scenario it aims to model.\\n    - *Algorithmic Bias*: Introduced by the assumptions and choices made during the algorithm development process.\\n    - *Confirmation Bias*: Arises when an AI system is designed in a way that it reinforces the beliefs or prejudices of its creators.\\n\\n#### Impacts of Bias\\n\\n1. **Social and Ethical Implications**: Bias in AI can lead to unfair treatment of certain groups, amplifying existing social inequalities. In areas like recruitment, credit scoring, and law enforcement, biased AI systems can result in unfair or discriminatory outcomes.\\n\\n2. **Legal and Regulatory Concerns**: Many countries and regions are now looking into regulations to prevent biased AI practices. The European Unionâ€™s General Data Protection Regulation (GDPR), for instance, includes provisions that relate to automated decision-making and profiling.\\n\\n3. **Economic Effects**: Businesses relying on biased AI systems risk making flawed decisions, potentially leading to financial losses or reputational damage.\\n\\n#### Case Studies\\n\\n1. **Recruitment Tools**: Certain AI-driven recruitment tools have been found to exhibit gender bias, favoring male candidates over female candidates in certain job roles, based on biased historical hiring data.\\n\\n2. **Criminal Justice Systems**: AI systems used in predictive policing and sentencing have sometimes unfairly targeted minority communities, reflecting historical biases present in the criminal justice data.\\n\\n3. **Healthcare Algorithms**: Research has shown that some healthcare-related AI systems have provided less accurate diagnoses for certain racial groups, primarily due to the underrepresentation of these groups in the training data.\\n\\n#### Mitigating Bias in AI\\n\\n1. **Diverse and Representative Data**: Ensuring that training datasets are diverse and representative can help reduce data biases. This includes considering factors like race, gender, socio-economic status, and geography.\\n\\n2. **Algorithmic Transparency and Explainability**: Developing algorithms that are transparent and explainable can help identify and mitigate biases. This transparency is crucial for sensitive applications like healthcare and criminal justice.\\n\\n3. **Regular Auditing and Testing**: Regularly auditing AI systems for biased outcomes and continuously testing these systems in real-world scenarios are essential practices.\\n\\n4. **Ethical AI Frameworks**: Implementing ethical AI frameworks and guidelines in organizations can help in making conscious efforts to avoid biases in AI systems. This includes ethical training for AI developers and practitioners.\\n\\n5. **Community and Stakeholder Engagement**: Involving a diverse range of stakeholders, including those who are most likely to be affected by AI decisions, in the development process can provide valuable insights into potential biases.\\n\\n#### Future Perspectives\\n\\nLooking forward, the challenge of bias in AI is not insurmountable. With the increasing awareness and evolving technological tools, there is a growing potential to develop AI systems that are fairer and more equitable. The future of AI should be inclusive, ensuring that the benefits of AI are accessible to all sections of society and do not perpetuate existing disparities. \\n\\n#### Conclusion\\n\\nBias in AI is a multifaceted issue that requires a concerted effort from technologists, policymakers, and society at large to address. By acknowledging and actively working to mitigate bias, the future of AI can be shaped into a tool that works equitably for the betterment of all.']\n",
      "- Bias in Artificial Intelligence (AI) is a growing concern as AI permeates various aspects of our lives - such as healthcare, finance, law enforcement, and social media.\n",
      "- Bias in AI often originates from the data used to train the systems and can result in systematic and unfair discrimination.\n",
      "- There are three common types of biases: data bias, algorithmic bias, and confirmation bias.\n",
      "- Bias in AI has social, ethical, legal, regulatory, and economic implications - it can lead to unfair treatment of certain groups, raise regulatory concerns, and cause businesses to make flawed decisions.\n",
      "- Case studies show bias in AI affecting recruitment tools, criminal justice systems, and healthcare algorithms.\n",
      "- To mitigate bias in AI, it is important to ensure diverse and representative data, develop transparent and explainable algorithms, regularly audit and test AI systems, implement ethical AI frameworks, and involve a diverse range of stakeholders in the development process.\n",
      "- The future of AI has the potential to be fairer and more equitable, provided there's recognition, awareness, and active effort to mitigate bias.\n",
      "- Bias in AI is a complex problem that requires cooperation from technologists, policymakers, and society at large to provide solutions that are fair and beneficial to all.\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"{OpenAIAPIKey}\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI language model trained to summarize document.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize the document. Return in bullet points: {document}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(document)\n",
    "print(completion.choices[0].message.content)\n",
    "print(\"***\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
